# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {
# META     "lakehouse": {
# META       "default_lakehouse_name": "",
# META       "default_lakehouse_workspace_id": ""
# META     }
# META   }
# META }

# CELL ********************

# 1. INSTALACIÃ“N AUTOMÃTICA (La lÃ­nea mÃ¡gica que faltaba)
# Esto asegura que la librerÃ­a exista antes de intentar importarla
%pip install semantic-link-labs

# 2. IMPORTACIÃ“N Y LÃ“GICA
import sempy_labs as sl
import time

# --- CONFIGURACIÃ“N AUTOMÃTICA ---
# Al dejarlo en None, se aplicarÃ¡ al workspace y lakehouse actuales del notebook
MODEL_NAME = "F1_Gold_Model"  # AsegÃºrate de que este sea el nombre exacto

print(f"ğŸ”„ Iniciando remapeo automÃ¡tico del modelo: {MODEL_NAME}")

try:
    # 1. Remapear la conexiÃ³n (Cablear al Lakehouse actual)
    print("   ğŸ”Œ Buscando Lakehouse adjunto para reconectar...")
    sl.directlake.update_direct_lake_model_connection(
        dataset = MODEL_NAME,
        source_type = "Lakehouse",
        use_sql_endpoint = True
    )
    print("   âœ… ConexiÃ³n remapeada con Ã©xito.")

    # 2. Sincronizar el esquema (Leer las tablas nuevas)
    print("   ğŸ”„ Sincronizando esquema...")
    sl.directlake.direct_lake_schema_sync(
        dataset = MODEL_NAME
    )
    print("   âœ… Esquema sincronizado.")

    print("\nğŸš€ Â¡LISTO! El modelo ya apunta a tus datos locales.")

except Exception as e:
    print(f"\nâŒ Error: {e}")
    print("ğŸ’¡ PISTA: Â¿Has aÃ±adido un Lakehouse al panel izquierdo ('Lakehouses') de este notebook?")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }
